# BiLSTM Models with and Without Pretrained Embeddings and BERT on German Patient Reviews
## Paper Link in IEEE-https://ieeexplore.ieee.org/abstract/document/10582115
ğŸ“„ *Published in:* 2024 International Conference on Advances in Modern Age Technologies for Health and Engineering Science (AMATHE)  
ğŸ“… *Date:* May 16, 2024  
ğŸ“ *Pages:* 1â€“5  
ğŸ“š *Publisher:* IEEE  
ğŸ”— *Citations:* Cited by 7 (as of 2025)

---

## ğŸ§  Overview

This repository accompanies the research paper:

> **"BiLSTM Models with and Without Pretrained Embeddings and BERT on German Patient Reviews"**  
> *Authors:* Prosenjit Roy, Md Jahid Alam Riad, Lija Akter, Nobanul Hasan, Mahfuzur Rahman Shuvo, Montaser Abdul Quader, Mozdaher Abdul Quader, Ahmed Selim Anwar

This study explores deep learning techniques for **sentiment analysis** in the healthcare domain, using a large dataset of German patient reviews. The models evaluated include:

- **BiLSTM with random embeddings**  
- **BiLSTM with pretrained word embeddings (e.g., GloVe/word2vec)**  
- **BERT (Bidirectional Encoder Representations from Transformers)**

Our objective was to determine which approach most accurately classifies patient sentiments as either **â€˜poorâ€™** or **â€˜excellentâ€™**.

---

## ğŸ” Problem Statement

Healthcare platforms often gather large volumes of unstructured patient feedback. Automatically analyzing such feedback can:

- Help healthcare providers improve services  
- Enable patients to make informed decisions  
- Streamline review classification tasks at scale  

This research evaluates the effectiveness of different NLP models in understanding and classifying sentiment expressed in **German-language medical reviews**.

---

## ğŸ“Š Dataset

- Source: Patient review platform (approx. 500,000 reviews)  
- Data includes:
  - **Numerical rating** (used as label: â€˜poorâ€™ or â€˜excellentâ€™)
  - **Free-text review comment**

### ğŸ”§ Preprocessing:
- Lowercasing, tokenization, stop-word removal
- Padding for BiLSTM models
- SentencePiece tokenizer for BERT input

---

## ğŸ“ˆ Key Results

| Model                          | Accuracy | F1 Score | Remarks                            |
|-------------------------------|----------|----------|-------------------------------------|
| BiLSTM (Random Embeddings)     | ~78%     | ~0.76    | Underperformed due to sparse vocab |
| BiLSTM (Pretrained Embeddings) | ~83%     | ~0.81    | Improved contextual understanding  |
| **BERT (German model)**        | **89%**  | **0.88** | Best performance, robust results   |

The BERT-based model outperformed both BiLSTM architectures in accuracy and class balance, demonstrating the strength of transformer-based models in multilingual sentiment analysis.

---

## ğŸ—‚ï¸ Repository Structure

```bash
â”œâ”€â”€ data/                   # Sample dataset (anonymized)
â”œâ”€â”€ preprocessing/          # Scripts for data cleaning and transformation
â”œâ”€â”€ models/                 # BiLSTM and BERT implementations
â”œâ”€â”€ results/                # Metrics, confusion matrix, and visualizations
â”œâ”€â”€ notebooks/              # Experimentation and analysis notebooks
â”œâ”€â”€ paper/                  # Published paper and citation info
â””â”€â”€ README.md               # Project overview
